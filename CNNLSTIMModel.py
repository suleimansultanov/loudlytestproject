import matplotlib.pyplot as plt
import librosa
import numpy as np
import glob
import os
from tensorflow.keras.losses import BinaryFocalCrossentropy
import scipy.signal
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Flatten, Dropout, Conv1D, MaxPooling1D, BatchNormalization

X_train, y_train = [], []

audio_dir = 'datasethiphop/audio'
beats_dir = 'datasethiphop/annotations'

audio_files = sorted(glob.glob(os.path.join(audio_dir, '*.wav')))

for audio_path in audio_files:
    file_id = os.path.splitext(os.path.basename(audio_path))[0]
    beat_path = os.path.join(beats_dir, f'{file_id}.beats')

    if not os.path.exists(beat_path):
        print(f"–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –¥–ª—è {audio_path}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        continue

    # –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ
    y, sr = librosa.load(audio_path, sr=22050, duration=30)

    # **–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä**
    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64, fmax=4000)
    S_DB = librosa.power_to_db(S, ref=np.max)
    X_original = np.expand_dims(S_DB.T, axis=-1)
    X_train.append(X_original)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –±–∏—Ç–æ–≤
    beat_times = np.loadtxt(beat_path)
    beat_frames = librosa.time_to_frames(beat_times, sr=sr)
    y_label = np.zeros((X_original.shape[0], 1))
    beat_frames = beat_frames[beat_frames < len(y_label)]
    y_label[beat_frames] = 1
    y_train.append(y_label)

    # **Augmentation: –¥–æ–±–∞–≤–ª—è–µ–º —à—É–º**
    y_noise = y + 0.005 * np.random.randn(len(y))
    S_noise = librosa.feature.melspectrogram(y=y_noise, sr=sr, n_mels=64, fmax=4000)
    S_DB_noise = librosa.power_to_db(S_noise, ref=np.max)
    X_noise = np.expand_dims(S_DB_noise.T, axis=-1)
    X_train.append(X_noise)
    y_train.append(y_label)  # –ú–µ—Ç–∫–∏ —Ç–µ –∂–µ —Å–∞–º—ã–µ

    # **Augmentation: –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (—É—Å–∫–æ—Ä–µ–Ω–∏–µ)**
    y_fast = librosa.effects.time_stretch(y, rate=1.1)
    if len(y_fast) >= sr * 30:  # —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–ª–∏–Ω–∞ –Ω–µ –º–µ–Ω—å—à–µ 30 —Å–µ–∫.
        y_fast = y_fast[:sr*30]
    else:
        y_fast = np.pad(y_fast, (0, max(0, sr*30 - len(y_fast))), mode='constant')

    S_fast = librosa.feature.melspectrogram(y=y_fast, sr=sr, n_mels=64, fmax=4000)
    S_DB_fast = librosa.power_to_db(S_fast, ref=np.max)
    X_fast = np.expand_dims(S_DB_fast.T, axis=-1)
    X_train.append(X_fast)
    y_train.append(y_label)  # –ú–µ—Ç–∫–∏ —Ç–µ –∂–µ —Å–∞–º—ã–µ

# –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
X_train = np.concatenate(X_train, axis=0)
y_train = np.concatenate(y_train, axis=0)

print("–î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã (—Å augmentation):", X_train.shape, y_train.shape)


model = Sequential([
    # –ü–µ—Ä–≤—ã–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
    Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1)),
    BatchNormalization(),
    MaxPooling1D(2),

    # –í—Ç–æ—Ä–æ–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
    Conv1D(64, 3, activation='relu'),
    BatchNormalization(),
    MaxPooling1D(2),

    # LSTM-–±–ª–æ–∫ (–∞–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π)
    LSTM(128, return_sequences=True),
    Dropout(0.3),
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π —Å–ª–æ–π
    LSTM(64, return_sequences=True),
    
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),

    # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–π –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–±–∏—Ç –∏–ª–∏ –Ω–µ –±–∏—Ç)
    Dense(1, activation='sigmoid')
])

# –ö–ª–∞—Å—Å–æ–≤—ã–µ –≤–µ—Å–∞, —É—á–∏—Ç—ã–≤–∞—é—â–∏–µ –¥–∏—Å–±–∞–ª–∞–Ω—Å (–ø–æ–¥–±–µ—Ä–∏ –ø–æ–¥ —Å–µ–±—è)
class_weights = {0: 0.1, 1: 0.9}

model.compile(optimizer='adam', 
              loss=BinaryFocalCrossentropy(gamma=2.0), 
              metrics=['accuracy'])

model.fit(X_train, y_train, epochs=42, batch_size=16, class_weight=class_weights)
# –û–±—É—á–µ–Ω–∏–µ

audio_path = 'loudly.mp3'
y_test, sr_test = librosa.load(audio_path, sr=22050, duration=30)

S_test = librosa.feature.melspectrogram(y=y_test, sr=sr_test, n_mels=64, fmax=4000)
S_DB_test = librosa.power_to_db(S_test, ref=np.max)

X_test = np.expand_dims(S_DB_test.T, -1)

# –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —É–¥–∞—Ä—ã
# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –±–∏—Ç–æ–≤
predicted_beats = model.predict(X_test).flatten()

# –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (—Å–∏–ª—å–Ω–µ–µ –º–µ–¥–∏–∞–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä)
smoothed_beats = scipy.signal.medfilt(predicted_beats, kernel_size=9)

# –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥
beat_threshold = np.mean(smoothed_beats) + np.std(smoothed_beats) * 0.5
beat_frames = np.where(smoothed_beats > beat_threshold)[0]

beat_times = librosa.frames_to_time(beat_frames, sr=sr_test)

# –£–±–∏—Ä–∞–µ–º —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã–µ –∏ —Å–ª–∏—à–∫–æ–º —Ä–µ–¥–∫–∏–µ –ø–∏–∫–∏ (—É–ª—É—á—à–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)
min_interval = 0.3  # 200 –º—Å –º–µ–∂–¥—É –±–∏—Ç–∞–º–∏ (~300 BPM –º–∞–∫—Å–∏–º—É–º)
final_beats = [beat_times[0]] if beat_times.size else []

for time in beat_times[1:]:
    if time - final_beats[-1] > min_interval:
        final_beats.append(time)

final_beats = np.array(final_beats)


if len(final_beats) > 1:
    bpm = 60 / np.mean(np.diff(final_beats))
    print(f"Calculated BPM: {bpm:.2f}")
else:
    print("Not enough beats detected to calculate BPM.")

plt.figure(figsize=(12, 4))

# üîπ –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤–æ–ª–Ω—É –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
librosa.display.waveshow(y_test, sr=sr_test, alpha=0.6, color='b')

plt.title("Waveform with Detected Beats")
plt.xlabel("Time (seconds)")
plt.ylabel("Amplitude")
plt.ylim(-1, 1)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∞–º–ø–ª–∏—Ç—É–¥—É
plt.show()